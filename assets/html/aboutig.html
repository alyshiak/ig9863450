<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../css/reset.css">
    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="../images/icon.png">

<!-- Using Tailwind instead of Bootstrap to provide CSS -->

    <script src="https://cdn.tailwindcss.com"></script>


    <title>About IG</title>
</head>


<body class="m-0 bg-white">

<!-- Header section -->

<header>
    <div
        class="h-auto  p-0 flex flex-col justify-between items-center bg-gray-900 text-white w-full sm:flex-row">
        <!-- CSS parameters used by Tailwind -->
        <div class="pl-3 flex justify-between">
            <div class=" flex sm:flex-row md:justify-start flex-col items-center">
                <img class="w-20" src="../images/icon.png" alt="logo">
                <a href="../../index.html"><span class=" text-2xl font-semibold py-1">ImageGenie</span></a>

            </div>
        </div>

        <ul class=' block py-2 text-center sm:inline  '>
            <li class="py-2 hover:bg-gray-600 w-[200px] block cursor-pointer sm:px-5 sm:inline ">
                <a href="./aboutig.html">About IG</a>
            </li>
            <li class="py-2 hover:bg-gray-600 w-[200px] block cursor-pointer sm:px-5 sm:inline ">
                <a href="./team.html">Team</a>
            </li>
            <li class="py-2 hover:bg-gray-600 w-[200px] block cursor-pointer sm:px-5 sm:inline ">
                <a href="./roadmap.html">Roadmap</a>
            </li>
        </ul>

    </div>
</header>

    <section class="md:items-top rounded-lg flex flex-row flex-wrap  text-justify justify-center mt-12">

        <p class="relative mt-12 w-auto">
            <img src="../images/transform.jpg" alt="vincien backgrond image"
                class=" w-[250px] rotate-12 rounded-[180px] absolute z-[-1]">
            <img src="../images/icon.png" alt="Logo Image" class="w-[250px] rounded-[180px] relative ">
        </p>

        <div class=" md:w-6/12 md:text-left md:pl-10 py-10 w-9/12 text-center">
            <h1 class="text-xl inline font-extrabold text-xl">About ImageGenie</h1>
            <p class="leading-normal mt-5 block text-justify">ImageGenie was created using AI technology which gives you the 
                power to generate an image based off a simple prompt or to screen a tweet for discrimination 
                of any kind.
                
                <br><br>Vincent, named after the artist Vincent Van Gogh, allows you to create an image with a 
                simple prompt of what you would like the image to be. You can be creative with your prompts and 
                create art, funny images, realistic images, characters etc. The posibilities are endless with 
                Vincent.

                <br><br>TweetInspector is a service which screens a Tweet for any form of discrimination. 
                Simply enter the Tweet which has been posted or you would like to post and you will be returned 
                an answer stating whether or not the Tweet in question contains any discrimation towards race, 
                gender, age etc. 
               <br><br>Both our applications use AI models build and managed by OpenAI Inc. In our applications
                we have used their DALLE and Davinci modals to provide our users with the the content which could meet their 
                requirement. 
                
            </p>
            <br><br><br>
            <p class="text-left leading-normal">


                <h1 class="text-left text-xl inline font-extrabold">How to get best results with Vincent</h1><br>
                <br>
                <br>
                <p class="  mt-5 block text-justify">
                    <ul class="ml-3 list-decimal leading-normal text-left">
                        <li>
                            Use clear and specific language when describing the image you want to generate. The more detailed and specific your text, the better the image generated will be.

                        </li><br>
                        <li>
                            Provide context for the image you want to generate. This can include information about the location, time period, or setting in which the image should be set.

                        </li><br>
                        <li>
                            Use a variety of adjectives and descriptive words to give the engine a better understanding of the image you want to generate.

                        </li><br>
                        <li>
                            Experiment with different text inputs and see how the engine responds. You may find that small changes in your text can result in big changes in the generated image.

                        </li><br>
                        <li>
                            Be patient, Vincent uses DELL-E which a complex model that takes time to generate images and also it's not perfect, so don't expect a perfect image everytime.

                        </li><br>
                        <li>
                            Adjust your input to improve image generation results.

                        </li><br>
                    </ul>

                    
                    <h1 class="text-left text-xl inline font-extrabold">Limitations of Vincent</h1><br>
                    <br>
                    <br>
                    <p class="  mt-5 block text-justify">
                        <ul class="ml-3 list-decimal leading-normal text-left">
                            <li>
                                Vincent uses machine learning and neural networks, which means that it may not always produce accurate or high-quality images.

    
                            </li><br>
                            <li>
                                It can be prone to biases, as it is trained on a dataset that may contain biases.

    
                            </li><br>
                            <li>
                                It is not capable of understanding the context behind the text input, so it may generate images that are not relevant or appropriate for the text provided.

    
                            </li><br>
                            <li>
                                It not capable of understanding the real-world situations or common sense, so it may generate images that are unrealistic or impossible.

    
                            </li><br>
                            <li>
                               Vincent uses DALL-E which is a newer model and is still being improved and developed, so there might be some limitations that will be addressed in the future.
    
                            </li><br>
                        </ul>
    
                    
                    
                        <h1 class="text-left text-xl inline font-extrabold">Limitations of TweetInspector</h1><br>
                        <br>
                        <br>
                        <p class="  mt-5 block text-justify">
                            <ul class="ml-3 list-decimal leading-normal text-left">
                                <li>
                                    TweetInspector uses OpenAI's machine learning model and neural networks, which means that it may not always produce accurate or coherent text.

        
                                </li><br>
                                <li>
                                    It can be prone to biases, as it is trained on a dataset that may contain biases.
    
        
                                </li><br>
                                <li>
                                    It is not capable of understanding the context behind the text input, so it may generate text that is not relevant or appropriate for the situation.
    
                                </li><br>
                                <li>
                                    It may struggle to understand idiomatic expressions, sarcasm or irony.    
        
                                </li><br>
                                <li>
                                    It is not capable of understanding the emotions, sentiment or feelings behind the text input, so its analysis may not catch those.        
                                </li><br>
                            </ul>
    
                 
                </p>


            </p>
        </div>

        </p>
    </section>

    <footer class="mt-30">
        <br><br>
        <div class="bg-gray-900 p-0 text-white flex flex-row justify-center items-center text-center footer-section">
            <p>Powered by </p>
            <img class = "w-20" src="../images/openai.png" alt="openai logo">
        </div>
    </footer>
    <script src="../js/script.js"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>

</body>

</html>